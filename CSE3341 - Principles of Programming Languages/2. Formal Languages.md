The basis for the design and implementation of programming languages are its alphabet, string, and language. A **language** is a set of **strings**, which are a finite sequence of symbols. The **alphabet** is the finite set of symbols that may be present within a string. 
# Formal Grammars
Grammar is defined as the finite set of **non-terminal** and **terminal** symbols, and the finite set of **productions**. 

We follow the Chomsky hierarchy, where regular languages $\subset$ context-free languages $\subset$ context-sensitive languages $\subset$ unrestricted languages. Regular languages in programming langages are used for **lexical analysis** and context-free languages are for **syntax analysis**. 
# Regular Languages

When interpreting and compiling code, we need a scanner and a parser to process the text. We begin with a stream of characters. First, a **scanner** takes the stream and performs lexical analysis using regular language to convert characters into a stream of tokens. Then, the parser uses a context-free language to perform syntax analysis to turn the tokens into a **parse-tree**. It is then further processed. 

We use regular expressions to express languages constructed by certain operations. A **regular expression** is (given some alphabet) the empty string $\epsilon$, any symbol from the alphabet, or some combination of the grammar in a valid order. 
# Regular Grammars
If all productions in a grammar have non-terminals only on the left side, it is a left-regular grammar (such as A->Bw and A->w). The opposite is a right-regular grammar. Regular grammars may only have one non-terminal on the result side, and result in one sequence of non-terminals. 

For example, I->D|DI and D-> 0|1|...|9 is not regular, but I->(0|1|...|9)|(0I|1I|...|9I) is right-regular. 

Lexical analysis (regular languages) is used within compilers to interpret characters and tokens. It is also used for pattern matching. 
# Context-Free Languages
Context-free languages are generated by a **context-free grammar**. Here, we change to use Backus-Naur form, which is a traditional alternative notation for CFGs. The main difference is that BNF defines non-terminals as \<name> instead of N. and the arrow becomes ::=. 

We use **derivation trees** (aka parse trees or concrete syntax trees) to derive a string. With these, every derivation step is a node in the tree, which branches off into the result of what that operation would be. The leaf nodes are terminals, inner nodes are non-terminals, and the root is the starting non-terminal of the grammar. 

Derivation trees describe a particular way to derive a string based on a context-free grammar. Leaf nodes, from the left to right, are the resulting string, and to get this string, we need to perform a depth-first traversal of the tree from left to right. 

