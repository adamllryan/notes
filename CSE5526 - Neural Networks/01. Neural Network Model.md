---
id: 01. Neural Network Model
aliases: []
tags: []
---

This section covers texbook sections 1, 2, 3, 4, 6, and 8.

## 1 Neural Networks

Neural Networks are a biologically-inspired approach for learning to complete a task that may be easy or natural for humans. This is accomplisher with a set of connected artificial neurons, a learning algorithm, and data. They derive their benefits from its parallel, distributed structure and its ability to learn and [[Generalization|generalize]].

Neural networks can be useful for the following tasks:

- Nonlinear approximation
- Input-output mapping, or modifying weights to map input data to the correct results
- Adaptivity
- Evidential response
- Contextual information, understanding problems with context
- Fault tolerance
- VLSI implementability, or able to be very scalable
- Uniformity of analysis and design
- Neuralbiological analogy  
  In short, it's good for just about anything traditional computing can't easily solve.

## 2 Human Brain Parallel

The _human cerebral cortex_ has regions that are sensitive to different stimuli. These regions are known as topographic maps. This part of the brain is divided into four lobes:

- occipital
- temporal
- parietal
- frontal

The brain is filled with neurons, which generate electric pulses and respond to stimuli. These responses can occur within milliseconds, and can continue for several hundreds of milliseconds. Neighboring neurons often show common responses. Our brain is made of roughly 10^11 neurons, each connected to (on average) 10^4 neurons. Because of this, our brain is an interconnected neural network.

### Neurons

A neuron has a tree-like structure. The main components of these are:

- Dendrites, which receive signals
- Cell body, generates signal
- Axon, Channel for impulses
- Synapse, terminates impulse

_Excitatory_, or positive responses are where a neuron on the receiving side increases activity, and _inhibitory_ is the reverse where activity is decreased. A neuron will only fire when it receives enough excitatory connections.

In short, a **neuron** is a unit or node, a **synapse** is a connection or architecture, and the **synaptic weight** is the connection strength, either positive or negative.

## 3 Neuron Models

The neural model encapsulates three basic elements: the weights, adder, and activation function. Each neuron links to another neuron via a weight, or a value that represents the strength of that particular link. It also has an adder, whose result is the sum of all the links multiplied by their respective weights (the weighted sum of the inputs). Finally, we have the activation function, which takes the weighted sum previously calculated and performs something on it to calculate the intended activation level of that neuron.

Normally, the activation function will normalize its output to be between $[-1,1]$ or $[0,1]$.

STOPPED AT PAGE 11
