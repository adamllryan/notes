# Brain
The *human cerebral cortex* has regions taht are sensitive to different stimuli. These regions are known as topographic maps. This part of the brain is divided into four lobes: 
- occipital
- temporal
- parietal
- frontal

The brain is filled with neurons, which generate electric pulses and respond to stimuli. These responses can occur within milliseconds, and can continue for several hundreds of milliseconds. Neighboring neurons often show common responses. Our brain is made of roughly 10^11 neurons, each connected to (on average) 10^4 neurons. Because of this, our brain is an interconnected neural network. 

# Neurons

A neuron has a tree-like structure. The main components of these are: 
- Dendrites, which receive signals
- Cell body, generates signal
- Axon, Channel for impulses
- Synapse, terminates impulse

*Excitatory*, or positive responses are where a neuron on the receiving side increases activity, and *inhibitory* is the reverse where activity is decreased. A neuron will only fire when it receives enough excitatory connections.

In short, a **neuron** is a unit or node, a **synapse** is a connection or architecture, and the **synaptic weight** is the connection strength, either positive or negative. 

# Artificial Neuron

An artificial neuron has a few functions we may use: 

An **adder**, or weighted sum, or linear combiner, is a function that sums the weighted combination of our input signals. 
$u_k=\sum^m_{j=1}{w_{kj}x_j}$

**Activation potential** is the sum of the adder and bias, or $v_k=u_k+b_k$. We use **bias** as a "zero-th" input to shift the results of our activation function, or essentially use it as a way to control when our neuron fires. We can introduce bias after summing, or we can even treat it as its own fixed weight input. 

Our output is the result of passing $v_k$ into our activation function $\phi$, where $y_k=\phi(v_k)$. 

We can easily represent NNs with vectors, where we have an input vector and a weight vector. 
# McCulloch-Pitts Neuron Model
**McCulloch-Pitts** networks, developed in 1943, were a first class of abstract computing machines: finite-state automata. These can compute any logic boolean function. They take bipolar (or binary) input, and generates bipolar outputs. 

#### Emulating Logic Gates

We can emulate logic gates with MP neurons. 

For negation, we can use weight -1 and bias 0. 

For OR, we can use the weights 1 and bias 0. This works like below, except now any `True` will be `at least 0`. 

For AND, we can set the weights as 1 and the bias as -1. This will give us the output -2 and -1 for all false values and then a 1 for the true values. This means our function can be `True if output >= 0 else False`. 

# Artificial Neural Networks

We use two architectures of artificial networks: feed forward and recurrent networks. 

**Feed Forward** networks, when viewed as a graph, have no loops between nodes. **Recurrent** networks allow for loops in their graphs, meaning we can have our model pass its own values back into itself. 

When we describe a neural network, we classify them by the number of nodes in each layer and the number of layers it has. A layer is one "row" or "column" in the model, where each layer is activated sequentially, and is connected to the layer before and after. A 10-4-2 network is a network with 10 inputs, 4 hidden nodes, and 2 output nodes. We consider it a 2 layer network, though, because we don't consider input nodes as a layer. 

MP Neurons are limited to only bipolar inputs and outputs and we can't use it for learning because we have to guess the weights ourselves. 

# Rosenblatt (Perceptron) Neuron Model

Rosenblatt modified the MP neuron such that it could input and output real-valued values. It may take anywhere between $-\infty, \infty$ 

Neuron learning amounts to modifying the weights and bias of the network in order to achieve the desired goal. We can find a **decision boundary** as a separator for our true and false output values. We use $g(x)$ to denote decision boundaries (**discriminant function**). 

Essentially, a perceptron is a neuron that specifically has an activation function that outputs `1 if output >= 0 else 0`. 

The decision boundary is equal to zero when $g(x)=\sum_{i=1}^mw_ix_i+b=0$, where $\sum_{i=1}^mw_ix_i+b$ is the activation potential of the perceptron. Perceptrons are **linearly separable** if they can be split by a line. 

We can plot a 2D decision boundary by taking the activation function, setting it to zero, and solving for one x. 

The **perceptron learning rule** is to strengthen the weight if the neuron fails to fire when it should have and to weaken it if it fires incorrectly. 

To do so, we use $w(n+1)=w(n)+\Delta(w)$ where $n$ is the iteration number and $\Delta(w)$ is the change in weight, defined as $\Delta(w)=r[d(n)-y(n)]x(n)$ where $r$ is learning rate, $d(n)$ is the desired output, and $y(n)$ is the actual output. I believe x(n) is the current weight. 

# Perceptron Convergence Theorem
The Perceptron Convergence Theorem states that a perceptron will reach a solution in a finite number of steps if it is linearly separable. A main goal in AI now is to figure out ways to transform data to be linearly separable. 

$w_0$ exists such that $d_pw^T_0x_p \geq \alpha > 0$ such that $\alpha=\text{min}_pd_pw^T_0x_p$. In essence, $\alpha$ is just the smallest numerical value amongst all of the data points. 

  

The perceptron learning rule is limited because it is used for MP neurons with real-valued inputs like perceptrons and it is used for binary classification only. 

  

The most common activation functions are:

- Sigmoid $\phi(v)=\frac{1}{1+e^{-v}}$
- Hyperbolic Tangent or $\phi(v)=\frac{2}{1+e^{-2v}}-1$
- Rectified Linear (ReLU), which is $\phi(v)=\text{max}(0,v)$

Prof states that he most often uses ReLU as an activation function. 

Linear activation functions ($\phi(v)[v$) is most often used for linear regression problems and statistics. The error for a linear neron is desired output - realized

#
