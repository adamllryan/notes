---
completed: true
next: "[[3. Search]]"
prev: "[[In Progress/Adv. Survey of Artifical Intelligence (CSE6521)/1. Introduction|1. Introduction]]"
---

Much of this content is a repeat of [[01_agent_design|this]] document. 

Much of AI is concerned with agents operating in environments. We refer to the **environment** as the problem setting and the **agent** as an entity that perceives and interacts with that environment via **effectors** (actuators). 

An agent's **percepts** are its sensors that give it information about its environment and its **effectors** allow it to manipulate the environment. 

**Consequentialism** is the concept that we can evaluate an agent's performance by the consequences of its actions. Generally, it is better to design performance measures to desired environment states rather than behavior, though. 

An agent is **rational** if it maximizes its expected performance measure for each possible percept sequence. Note that rationality is not the same as omniscience. Because there is uncertainty in environments, it is not reasonable to expect the agent to always produce the optimal results every time. 

| Property             | Description                                                                |
| -------------------- | -------------------------------------------------------------------------- |
| Fully Observable     | The agent can see everything                                               |
| Partially Observable | The agent has limited percepts                                             |
| Single Agent         | The agent plays against itself                                             |
| Multiagent           | The task involves multiple agents                                          |
| Deterministic        | The world is fully determined by the current state and the agent's actions |
| Nondeterministic     | There is uncertainty in the environment                                    |
| Episodic             | Each step's state is independent of other states                           |
| Sequential           | States affect later states                                                 |
| Static               | The world does not change while the agent thinks                           |
| Dynamic              | The world continues during decision making                                 |
| Discrete             | The world has discrete states                                              |
| Dynamic              | The world has continuous states                                            |
| Known                | The agent knows all of its rules                                           |
| Unknown              | The agent may not know all of the rules (its unknown lol)                  |

