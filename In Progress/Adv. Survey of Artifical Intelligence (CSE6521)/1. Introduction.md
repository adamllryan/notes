---
completed: true
next: "[[2. Agents]]"
prev: "[[]]"
---
**AI** is the science of making machines that think/act human/rationally. 

# Turing Test
We can use the **Turing Test** (which is outdated) to judge if an AI can "act like a human" by:
1. Placing a human judge and an unknown entity in two rooms. 
2. Give each a computer connected via chat. 
3. Have them converse for 5 minutes, and ask the judge to decide if they think the unknown is human or computer. 

The Turing test is outdated and is problematic. It is only concerned with the output and not the process, encouraging deception and hackery. It isn't reproducible and amendable to mathematical analysis. 

"Thinking like a human" via cognitive modeling is a similar idea to cognitive science. Often, we can use other methods to achieve the same results without actually thinking like a human. 

"Thinking rationally" is akin to "laws of thought". This is difficult, however, because it requires inference, which we ourselves cannot form concrete correct opinions for. 

"Thinking rationally" is the easiest goal, because it refers to the following:
- Maximally achieving pre-defined goals
- Focusing on the outcome, not the decisions made
- Maximizing expected **utility**

# AI Subfields
We have AI divided into subfields:
- Machine learning
- NLP
- CV
- robotics
- logic and knowledge representation
- speech processing
- game playing
- autonomous driving