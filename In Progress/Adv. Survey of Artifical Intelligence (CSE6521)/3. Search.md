---
completed: true
next: "[[4. Advanced Search]]"
prev: "[[2. Agents]]"
---

Agents that plan ahead must consider outcomes in the future. It needs a model of the world and how it changes as the agent makes decisions. These are called **planning agents**, who take information about the environment, simulate outcomes, and execute action sequences in the real environment. 

# Search Problems
A **search problem** is a systematic way of looking for the optimal action sequence that reaches a goal. A search problem consists of a **state space**, **successor function**, and **start/end state**. The solution is a sequence of actions that transform a start state into a goal state. 

A **state space graph** is a mathematical representation of a search problem where nodes are abstracted world configurations and arcs represent successors to each state. Each state may only occur once and these graphs are most likely far too large to build in full. 

A **search tree** begins at a start state and maps children to all successors of that root state. In a search tree, nodes are not states but partial plans, meaning that the node contains the start state path along with the states it must take to reach that end state. 

# Uninformed Search
**Uninformed search** occurs when the agent is given no information about how to find the goal state. It finds the goal state by systematically generating new states and testing for a goal. 

### Depth-First Search
This algorithm uses the expansion strategy of expanding the deepest node first. It is $O(b^m)$ time complexity, where $b$ is the breadth (width) of a layer and $m$ is the number of layers traversed. It is complete if $m$ is finite and is not optimal because it always finds the left-most solution. 

### Breadth-First Search
This algorithm checks the shallowest solutions first. It takes $O(b^s)$ time, where $s$ is the layer the solution exists on. It is complete because if $s$ is finite and optimal if costs are all 1. 

### Uniform-Cost Search
Uniform-cost search is sensitive to the cost of traversing between nodes by expanding the node with the lowest cost. UCS takes $O(b^{C^*/\epsilon})$ time where $C^*$ is the solution cost and $\epsilon$ is the arc cost. 

# Informed Search
**Informed search** is the opposite, where the agent is given some heuristic to find the goal state. It can use both metrics from uninformed search as well as the heuristic to find the goal state. A **heuristic** is a function that (over) estimates how close a state is to a goal. 

### Greedy Search
Greedy search expands the node that it thinks is closest to the goal. Best case, it takes the agent right to the goal and worst case it acts like a badly guided depth-first search. 

### A* Search
This algorithm combines greedy and uniform-cost search by summing the UCS backward cost $g(n)$ and the greedy forwards cost $h(n)$ by $f(n)=h(n)+g(n)$. 

## Admissible Heuristics
A heuristic is **admissible** if: $0 \leq h(n) \leq h^*(n)=g(G)-g(n)$ where $h^*(n)$ is the true cost to reach the goal. 

