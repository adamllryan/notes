---
completed: false
next: 
prev: 
---


SERIALIZABILITY

---

# Optimistic Concurrency Control (OCC)

Unlike pessimistic locking, **Optimistic Concurrency Control (OCC)** executes transactions without any concurrency control and validates the execution before committing. If validation fails, the transaction is rolled back.

### Process
1. Assign a timestamp to the transaction.
2. During execution, read from the database and create a copy.
3. After execution, validate and either commit or roll back the transaction.

---

# Snapshot Isolation

With **snapshot isolation**, a transaction operates on a snapshot of the database. Before committing, it checks if any of the objects it modified were updated by other transactions. If not, the transaction is committed; otherwise, it is rolled back.

Here is an explanation of the topics covered in your lecture slides in markdown format:

---

## Definition of a Distributed System
A **distributed system** is a collection of independent computers that appears to users as a single coherent system. This system may consist of multiple computers that communicate and coordinate their actions via a network.

---

## Distributed System Organization
Distributed systems can be organized using **middleware**, which serves as a bridge between different components of the system. The **thickness** of the middleware can vary, depending on the degree of integration of the system.

---

## Hardware Organization in Distributed Systems
### Models:
1. **Each machine with its own memory and storage**: Machines communicate via network packets.
2. **Shared-memory model**: All machines can access memory directly, which simplifies distributed programming by emulating a multi-threaded environment.

---

## Key Terminologies in Distributed Systems

1. **Throughput**: The number of requests processed per second.
2. **Latency**: The time it takes to process a single request.
3. **Scalability**: Whether adding more machines increases throughput.
4. **Consistency**: Correct behavior of the system.
5. **Availability**: How quickly the system responds to client requests.
6. **Liveness**: Whether the system eventually processes a request.
7. **Durability**: Whether the system can lose data or not.
8. **Fault Tolerance**: Ensuring consistency, liveness, and durability despite system failures.

---

## Process Communication Models

1. **Message Passing Model**:
   - Processes communicate explicitly by sending and receiving messages.
   - Used in distributed applications and parallel programming.
   
2. **Remote Procedure Call (RPC) Model**:
   - Communication is implicit, mimicking a local procedure call.
   - The complexity lies in message packing and unpacking (stubs).
   
3. **Remote Direct Memory Access (RDMA)**:
   - Allows a client to read/write to the memory of a remote machine without CPU/OS involvement.
   - Offers high performance but can be complex to use.

---

## Process Communication: Sockets and RPC

### Socket Communication (TCP/IP)
Basic socket primitives include:
- **Socket**: Create a new communication endpoint.
- **Bind**: Attach a local address to a socket.
- **Listen**: Announce willingness to accept connections.
- **Accept**: Wait for incoming connections.
- **Connect**: Establish a connection.
- **Send/Receive**: Exchange data.
- **Close**: Terminate the connection.

### Remote Procedure Call (RPC)
In RPC, processes communicate via messages, but the interaction looks like a local procedure call. **Client and server stubs** handle message packing and unpacking, making the communication transparent to the developer.

---

## Topics in Distributed Systems

1. **Distributed Deadlock Detection**: Detecting and resolving deadlocks in a distributed environment.
2. **Distributed Mutual Exclusion**: Ensuring exclusive access to shared resources in a distributed system.
3. **Distributed Transaction Execution**: Coordinating transactions across multiple systems.
4. **Fault Tolerance**:
   - **Quorum-based approach**: Requiring a majority to reach consensus.
   - **Leader-based approach (Paxos, PBFT)**: Electing a leader to coordinate actions and reach consensus.
5. **Consistency**: Ensuring that all nodes in the system have a consistent view of the data.

---

## Topics of Distributed System Section
- **Distributed Deadlock Detection**:
  - **Global State and Distributed Snapshot**: Capturing a consistent snapshot of the global state.
  - **Logical and Vector Clocks**: Methods to order events in a distributed system.
- **Distributed Mutual Exclusion**: Algorithms to ensure exclusive access to shared resources.
- **Distributed Transaction Execution**: Executing transactions across multiple distributed nodes.
- **Fault Tolerance**:
  - **Quorum-Based Approach**: Using a majority to make decisions.
  - **Leader-Based Approach (Paxos, PBFT)**: Electing a leader to handle system consensus.
- **Consistency**: Ensuring a unified state across the distributed system.

---

## Model of a Distributed System
- **Machines connected by a network**.
- **Message transfer delay**:
  - **Synchronous model**: Delay has an upper bound.
  - **Asynchronous model**: Delay has no upper bound.

---

## Problem: Global State
- No single machine has access to the entire system state.
- There are situations when a **global state** is required:
  - Detecting deadlocks.
  - Checking the total balance of a bank.
  - Taking a checkpoint for future recovery.

---

## Issues with Simple Approaches
A simple approach, like asking each node for its state, may not work in scenarios like **deadlock detection** due to issues like:
- **Timing delays** in distributed systems.
- No **global clock**.
- **Non-negligible message transfer delays**.

A **counterexample** for deadlock detection demonstrates that just combining local states at arbitrary times can lead to incorrect conclusions.

---

## Events and Histories
- **Event types**: Local, send, and receive events.
- Each process has a sequence of events, which forms its **local history**.
- **Global history** is the union of all local histories across processes.

---

## Happened-Before Relation
- Introduced by **Leslie Lamport** (1978), this is a binary relation between events:
  1. **Within a process**: If one event happens before another in the same process, it is ordered.
  2. **Message events**: Sending a message happens before receiving it.
  3. **Transitivity**: If event A happens before event B, and B happens before event C, then A happens before C.

---

## Consistent Global State
A **global state** is consistent if, for any two events \( e_i \) and \( e_j \):
- If \( e_j \) happens after \( e_i \), and \( e_j \) is part of the global state, then \( e_i \) must also be included.

---

## Distributed Snapshot
The **Chandy-Lamport protocol** is used to capture a consistent global state:
1. **Global state** consists of the local state of each node and the state of messages in channels.
2. **Steps**:
   - A node is triggered to start the snapshot process.
   - This node records its state and sends a "take snapshot" message to other nodes.
   - Each node that receives this message records its state and relays the "take snapshot" message.
   - A node stops recording when it has received the "take snapshot" message from every other node.

---

## Space-Time Diagrams
These diagrams represent the execution of distributed processes across time. They help visualize the ordering of events and how a consistent snapshot is taken.

---

## Proof of Correctness: Chandy-Lamport Protocol
The correctness of this protocol ensures that events are recorded in a way that represents a consistent snapshot, even if message delays exist.

---

## Stable Properties
- **Stable properties** are those that, once true, remain true:
  - Examples: **Deadlock**, **termination**, and **garbage collection**.
- **Unstable properties** change over time, such as the number of online users or the amount of money in a bank.

---

Let me know if you need more detailed explanations for any specific part!

Here's an explanation of the key topics from the lecture slides:

## Absence of Global Clock

In distributed systems, synchronizing activities across different parts of the system is challenging due to the lack of a global clock. Some key points:

- Using a single shared clock is problematic because different processes can see the clock at different times due to unpredictable transmission delays[1].
- Even radio-synchronized clocks face issues with unpredictable propagation delays[1].
- Software approaches like clock synchronization algorithms and logical clocks are used to address this problem[1].

## Clock Synchronization Algorithms

### Cristian's Algorithm

- Basic idea: Get the current time from a time server[1].
- Challenges:
  - Error due to communication delay, which can be estimated
  - Time correction on the client must be gradual[1]

### Berkeley Algorithm

- A time daemon asks all machines for their clock values
- Machines respond with their times
- The time daemon then tells everyone how to adjust their clocks[1]

## Logical Clocks

Logical clocks are used to order events in a distributed system without relying on physical time.

### Lamport Clock

- Each node maintains a local integer called LC (Logical Clock)[1].
- Satisfies the clock condition: if event e happens before e', then clock(e) < clock(e')[1].
- Cannot provide gap detection or differentiate between concurrent and related events[1].

### Vector Clock

- Represents the minimal consistent cut that includes an event[1].
- Stronger than Lamport clocks, satisfying the strong clock condition: e happens before e' if and only if clock(e) < clock(e')[1].
- Allows for differentiating between concurrent and related events[1].

## Causal Delivery

- Ensures that if send(m) happens before send(m'), then deliver(m) happens before deliver(m')[1].
- Important for maintaining consistent global state in distributed systems[1].

## Data Race Detection

- Uses vector clocks to detect data races in concurrent programs[1].
- Basic idea: If there's a happened-before relationship between conflicting operations, there's no problem. Otherwise, it's a data race[1].
- Treats unlock operations as "send" and lock operations as "receive" to establish happened-before relationships[1].

## Vector Clock Properties

1. Strong Clock Condition: e → e' ≡ VC(e) < VC(e')
2. Simple Strong Clock Condition: ei → ej ≡ VC(ei)[i] ≤ VC(ej)[i]
3. Concurrent: ei || ej ≡ (VC(ei)[i] > VC(ej)[i]) ∧ (VC(ej)[j] > VC(ei)[j])
4. Weak Gap-Detection: VC(ei)[k] < VC(ej)[k] → ∃ek, s.t. ¬(ek → ei) ∧ (ek → ej)[1]

These topics form the foundation for understanding time and event ordering in distributed systems, which is crucial for maintaining consistency and detecting issues like data races in concurrent environments.

Citations:
[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/30921953/07b10fbd-1a5c-4bc4-8a87-c415061b9f69/lecture10-LogicalClock.pdf

Here are notes with definitions from the slide deck. I have marked definitions that I created from memory with an asterisk (*).

---

### Distributed Deadlock Detection
- **Distributed Deadlock Detection**: The process of detecting deadlock situations in a distributed system, where processes are waiting on each other in a cycle, across multiple machines or sites.

### Global State and Distributed Snapshot
- **Global State**: The combined state of all the nodes in a distributed system at a specific point in time.*
- **Distributed Snapshot**: A mechanism to capture the global state of a distributed system without halting its execution.*

### Logical Clock
- **Logical Clock**: A clock that provides an order of events in a distributed system without being synchronized to a real-time clock.*

### Vector Clock
- **Vector Clock**: An algorithm that provides a way of ordering events in a distributed system by maintaining a vector of logical clocks, one for each process.*

### Distributed Mutual Exclusion
- **Distributed Mutual Exclusion**: A protocol ensuring that multiple processes in different machines in a distributed system can enter a critical section without conflicts.*

### Distributed Transaction Execution
- **Distributed Transaction Execution**: The process of executing a transaction across multiple sites in a distributed system, ensuring consistency, isolation, and atomicity.*

### Fault Tolerance
- **Fault Tolerance**: The ability of a distributed system to continue functioning in the presence of faults or failures.*
- **Quorum-Based Approach**: A fault tolerance mechanism where a majority (or quorum) of components must agree on decisions for the system to proceed.
- **Leader-Based Approach**: A method where one node (the leader) is responsible for making decisions, such as Paxos and PBFT.

### Paxos
- **Paxos**: A consensus algorithm used to achieve agreement among a distributed group of machines even in the presence of failures.*

### PBFT (Practical Byzantine Fault Tolerance)
- **PBFT**: A consensus algorithm designed to tolerate Byzantine faults (arbitrary failures), ensuring agreement among nodes in a distributed system despite some behaving maliciously.*

### Consistency
- **Consistency**: A property of distributed systems where all nodes or copies of data reflect the same value after an operation.*

### Atomicity
- **Atomicity**: Ensures that a transaction either completes entirely or does not happen at all, leaving the system in a consistent state.

### Global Atomicity
- **Global Atomicity**: Ensures that either all operations in a distributed transaction across multiple sites commit, or none do, maintaining atomic behavior across the system.

### Common Knowledge
- **Common Knowledge**: A concept where all participants in a distributed system have the same knowledge and know that all others have the same knowledge, infinitely recursive.*

### Two-Generals Problem
- **Two-Generals Problem**: A classic problem illustrating the difficulty of achieving reliable communication and agreement between two parties when messages can be lost.*

### Two-Phase Commit Protocol (2PC)
- **Two-Phase Commit Protocol**: A consensus protocol used in distributed systems to ensure that all participants in a transaction either commit or abort the transaction to achieve atomicity.
  - **Phase 1**: The coordinator asks participants if they can commit.
  - **Phase 2**: If all agree, the coordinator instructs them to commit; otherwise, it aborts the transaction.

### Coordinator
- **Coordinator**: In 2PC, the node responsible for initiating and managing the commit or abort process across all participants.

### Cohort
- **Cohort**: The participant nodes in a distributed transaction that respond to the coordinator's commit request in 2PC.

---

Let me know if you need further clarifications or additions to these notes!