---
completed: false
next: "[[3. Virtualization]]"
prev: "[[1. Synchronization]]"
---

# Database
A **database** is a collection of shared data objects that can be accessed by multiple users. It has correctness constraints, also known as **consistency assertions** or **integrity constraints**. A database is considered **consistent** when its data satisfies these constraints.

## Transactions
Users interact with a database through **transactions**—a sequence of read, write, and computation operations on the database objects. Transactions are treated as a single logical unit of interaction.

- A **query** is a read-only transaction.
- An **update** modifies at least one object in the database.

We assume that transactions:
- **Preserve consistency** (i.e., maintain the database's integrity).
- **Terminate in finite time** (i.e., they will eventually complete).

Transactions use specific actions (called **primitives**) to interact with the database, such as:

| Primitive         | Description                                     |
| ----------------- | ----------------------------------------------- |
| BEGIN_TRANSACTION | Mark the start of a transaction                 |
| END_TRANSACTION   | Terminate the transaction and attempt to commit |
| ABORT_TRANSACTION | Kill the transaction and restore values         |
| READ              | Read data from file, table, or other            |
| WRITE             | Write data to file, table or other              |


## Transaction Implementation

There are two main methods to implement transactions:

### 1. Private Workspace Method
1. Create a copy of the data and modify it.
2. Verify the accuracy of the changes.
3. Remove the old version via deletion.

### 2. Write-Ahead Log (WAL) Method
1. Execute the transaction and record it in a log.
2. Commit the transaction by writing it to the database.
3. Roll back the changes using the log if an abort is triggered.
4. Delete the log after committing.

**Committed** means a transaction has been completed and does not need to be rolled back or aborted. As a result, the effects of a transaction become visible to others. This is implemented by unlocking or updating data to new values.

A log entry is **idempotent** if applying it multiple times will always produce the same value.

# Concurrency Control

**Concurrency control** ensures that multiple transactions can execute simultaneously while maintaining database consistency and isolation. It is managed by:
- The **Data Manager**
- The **Scheduler**
- The **Transaction Manager**

![[Screenshot 2024-09-10 at 1.37.04 PM.png]]

# ACID

[[10. Transaction Management#Concurrency Control|ACID]] is a property that means all or nothing, if it fails nothing happens. ACID stands for

- **Atomicity**: The transaction is all-or-nothing.
- **Consistency**: The transaction brings the database from one valid state to another.
- **Isolation**: Transactions do not see or affect each other's internal state.
- **Durability**: Once committed, the results of the transaction are permanent.

# Logs

A **log** is a sequence of chronologically ordered actions performed by transactions under a concurrency control algorithm. It is comprised of $r_i$ and $w_i$ messages, where $i$ is a number indicating the order of execution. Two logs are equivalent if they produce the same results given the same starting state.

- A **serial log** executes transactions one after the other with no overlap.
- A **serializable log** has the same outcome as a serial log, even though transactions may be interleaved.

### Conflict Serializability

We don't know if locks are serializable because it is an NP-hard problem, so we simplify it to **conflict serializable** or **view serializable** where conflict serializable implies view serializable.

Two logs are view serializable if they produce the same results. They are conflict serializable if you can swap non-conflicting executions in a way that is the same as a serial execution. 

Two executions conflict if:
1. They access the same data object.
2. At least one of them writes to the object (read-write, write-read, or write-write conflict).

### Serialization Graph

Suppose $L$ is a log over transactions $T_0,T_1,...,T_n$. Its **serialization graph** $SG(L)$ is a directed graph where the nodes are transactions $T_i$ and edges $T_i \rightarrow T_j$ is for some $x$ $r_i[x]<w_j[x]$ or $w_i[x] < r_k[x]$ or $w_x[x] < w_k[x]$. In other words, each node is a transaction and each edge represents conflicting executions with a happens-before relationship. 

**Serializability theorem**: A log $L$ is conflict serializable if and only if SG(L) is acyclic.

# Lock-based Algorithms

Lock-based algorithms control access to data by requiring transactions to acquire locks before accessing objects.

A transaction is **well-formed** if:
1. It locks the data before accessing it.
2. It does not lock the same data more than once.
3. It releases all locks before completing.

### Types of Locking

We consider two types of locking algorithms:

#### 1. Static Locking
- Transactions acquire all necessary locks at the beginning.
- Simple but lacks concurrency since transactions wait for others to release locks.

#### 2. Two-Phase Locking (2PL)
- Transactions lock data as needed, resulting in a **growing phase** (acquiring locks) and a **shrinking phase** (releasing locks). **Top point** is where it has all of its locks.
- May result in **deadlocks** or **cascading rollbacks**.
- **Strict 2PL**: Locks are held until the transaction completes, preventing cascading rollbacks.

# Timestamp-based Algorithms

These algorithms use **timestamps** to order conflicting transactions. Each transaction receives a unique timestamp, which the scheduler uses to resolve read/write conflicts. Typically, variants of Lamport's logical clocks are used to timestamp all transactions (covered later).

## Basic Timestamp Ordering
The idea behind this is to keep the transaction with the largest timestamp. This is ideal behavior because we want to abort any transaction late after another has already been committed. Below, $t$ refers to the timestamp of the incoming transaction, and we will want only to accept it if it is the latest accepted execution. 

For $\text{Read}(x, t)$:
- If $t < W_t(x)$, reject, and abort.
- Otherwise, execute and set $R_t(x)$ to $=\text{max}\{R_t(x),t\}$.

For $\text{Write}(x,t)$:
- If $t<R_t(x)$ or $t < W_t(x)$ reject, and abort.
- Otherwise, execute and set $W_t(x)$ to $t$.

This method involves significant **storage overhead** and frequent transaction aborts.

# Isolation Levels

**Isolation** controls how transaction results become visible to others. Higher isolation levels provide more data integrity but may reduce performance.

From strongest to weakest:
1. **Strict Serializability**: Transactions appear to execute in real time.
2. **Serializability**: Transactions' outcome is equivalent to some serial execution.
3. **Repeatable Reads**: Multiple reads within a transaction return the same value.
4. **Snapshot Isolation**: Each transaction operates on a personal snapshot of the database.
5. **Read Committed**: Only committed data is read (no dirty reads).
6. **Read Uncommitted**: Transactions can see uncommitted data.
7. **No Isolation**: Transactions can see all intermediate states.

In practice, many database systems do not use serializability. They may use another isolation level because higher levels of isolation come with poorer performance.

#### 1. Read Uncommitted
- Transactions can see changes made by other transactions, even before those changes are committed.
- Commonly implemented by using basic locking.
#### 2. Read Committed
- Transactions may read only committed data, preventing **dirty reads**. 
- Commonly implemented via:
	- **writes** hold the lock until the end of the transaction.
	- **reads** immediately release the lock after use.
#### 3. Snapshot Isolation
- Each transaction appears to operate on a personal snapshot of the database taken at the start of the transaction.
- Only commits if its updated objects are not changed by other transactions.
#### 4. Repeatable Reads (Definition 1)
- Alteration of read-committed that also prevents **non-repeatable read**. 
- Once a transaction reads a value, subsequent reads of the same data return the same result for the duration of the transaction. 
#### 5. Repeatable Reads (Definition 2)
- Based on locking, all locks are held until the end of the transaction. 
- This is the same as two-phase locking, making it very similar to serializability.
#### 6. Serializability
- Holds locks until the end of the transaction with range operation support. 
#### 7. Strict Serializable
- Serializability with a real-time guarantee. 

### Serializability Anomalies
1. **Write Skew**: Occurs when two concurrent transactions both read overlapping data but update disjoint pieces of that data based on their respective reads. This leads to inconsistent states because neither transaction sees the other’s update before committing.

2. **Non-repeatable Reads**: When a transaction reads the same data twice but gets different results because another transaction has modified the data in the meantime. This violates the consistency expected within a single transaction.

3. **Dirty Reads**: When a transaction reads uncommitted changes made by another transaction. If the other transaction rolls back, the first transaction has operated on invalid data.

4. **Phantom Reads**: When a transaction reads a set of records based on a condition, but another transaction inserts or deletes records that meet the condition. As a result, subsequent reads within the same transaction return different sets of records.

![[Screenshot 2024-10-08 at 9.29.19 AM.png]]

# Defining Isolation

We need to consider three kinds of edges:

- write dependency: write-write conflict
- read dependency: write-read conflict
- anti dependency: read-write conflict

# Optimistic Concurrency Control

Lock-based implementations are often called pessimistic solutions because they try to prevent bad interleaving from happening. Optimistic concurrency control (OCC), we execute transactions without concurrency controls and then validate the execution before committing.

At the beginning, record a timestamp for the transaction. During execution, read from DB to create a copy. Then validate and commit or rollback depending on the results.

**Snapshot isolation**, before the first transaction commits, validates whether an object updated by that transaction was modified by others after it has started.

# Concurrency Control Issues

A **deadlock** occurs when processes are permanently blocked due to waiting for the same shared resource(s). It is a cycle in the wait-for graph.
**Starvation** is when a transaction is always waiting for a resource and never gets it.

## Causes of Deadlocks

A deadlock occurs when four conditions are met:

- Exclusive access: a process requires exclusive access to a resource.
- Hold and wait: a process holds a resource and waits for another.
- No preemption: resources cannot be preempted.
- Circular wait: a cycle in the wait-for graph.

The first three conditions are generally desirable, but the fourth is not.

## Deadlock Handling Policies

- **Deadlock detection**: detect and recover from deadlocks.
- **Deadlock avoidance**: ensure that a cycle in the wait-for graph is not created.
- **Deadlock prevention**: ensure that at least one of the four conditions is not met.

## Deadlock Analysis

Deadlock analysis is complicated by the number of variants of the process-resource relationship:

- how many/which resources are needed.
- how many times a resource can be used.
- how many processes can simultaneously use a resource.

## Deadlock Models

Depending on the type of resource request, a deadlock can be classified as:

- **Single-unit request model**: vanilla??
- **AND request model**: a process requests multiple resources at once.
- **OR request model**: a process requests one of multiple resources.
- **AND-OR request model**: a process requests multiple resources, but only one of each type.
- **P-out-of-Q request model**: a process requests P out of Q resources.

## Types of Resources

- **Reusable resources**: can be used by multiple processes.
- **Consumable resources**: can be used only once.
- **Exclusive resources**: can be used by only one process at a time.
- **Shared resources**: can be used by multiple processes.

## Theory vs. Practice

There is a whole theory for analyzing different variants. In practice, however, we use a combination of deadlock prevention, avoidance, and detection.

- Reusable: acquire a lock and release it when done.
- Single-unit: No atomic operation to acquire multiple resources.
- Exclusive: No deadlock.

### Deadlock Detection

Periodically check for deadlocks. We can tell if there is a deadlock using a wait-for graph. If there is a cycle, there is a deadlock.

In practice, we need to pause the system to check for deadlocks. This is slow and inefficient. Distributed protocols are a better alternative to this.

### Deadlock Avoidance

Avoid creating a cycle in the wait-for graph. This can be done by ensuring that the system is in a safe state. A state is safe if there is a sequence of transactions that can be executed without causing a deadlock.

The **Banker's algorithm** is an example of deadlock avoidance. It ensures that the system is in a safe state before granting a request.

This algorithm uses a checking algorithm to determine if a state is safe:

1. Check if any process can finish with the available resources.
2. If it can, execute the process and release the resources.
3. If there is at least one process that cannot finish, the state is unsafe.
4. Otherwise, the state is safe.

# Distributed Systems

