---
id: 03. Perceptrons
aliases: []
tags: []
---
## Rosenblatt (Perceptron) Neuron Model

Rosenblatt modified the MP neuron such that it could input and output real-valued numbers. It may take anywhere between $-\infty, \infty$

Neuron learning amounts to modifying the weights and bias of the network in order to achieve the desired goal. We can find a **decision boundary** as a separator for our true and false output values. We use $g(x)$ to denote decision boundaries (**discriminant function**).

Essentially, a perceptron is a neuron that specifically has an activation function that outputs `1 if output >= 0 else 0`.

The decision boundary is equal to zero when $g(x)=\sum_{i=1}^mw_ix_i+b=0$, where $\sum_{i=1}^mw_ix_i+b$ is the activation potential of the perceptron. Perceptrons are **linearly separable** if they can be split by a line.

We can plot a 2D decision boundary by taking the activation function, setting it to zero, and solving for one x.

The **perceptron learning rule** is to strengthen the weight if the neuron fails to fire when it should have and to weaken it if it fires incorrectly.

To do so, we use $w(n+1)=w(n)+\nabla(w)$ where $n$ is the iteration number and $\nabla(w)$ is the change in weight, defined as $\nabla(w)=r[d(n)-y(n)]x(n)$ where $r$ is learning rate, $d(n)$ is the desired output, and $y(n)$ is the actual output. $x(n)$ is the current input vector.

## Perceptron Convergence Theorem

This section covers Chapter 2 and 3, sections 2.1, 2.2, 3.1, 3.2, 3.3, 3.5, and 3.13.

The Perceptron Convergence Theorem states that a perceptron will reach a solution in a finite number of steps if it is linearly separable. A main goal in AI now is to figure out ways to transform data to be linearly separable.

$w_0$ exists such that $d_pw^T_0x_p \geq \alpha > 0$ such that $\alpha=\text{min}_pd_pw^T_0x_p$. In essence, $\alpha$ is just the smallest numerical value amongst all of the data points.

The perceptron learning rule is limited because it is used for MP neurons with real-valued inputs like perceptrons and it is used for binary classification only.

The most common activation functions are:

- Sigmoid $\phi(v)=\frac{1}{1+e^{-v}}$
- Hyperbolic Tangent or $\phi(v)=\frac{2}{1+e^{-2v}}-1$
- Rectified Linear (ReLU), which is $\phi(v)=\text{max}(0,v)$

Prof states that he most often uses ReLU as an activation function.

Linear activation functions ($\phi(v)[v$) is most often used for linear regression problems and statistics. The error for a linear neron is the desired output - realized

## Least Mean Squares

To estimate unknown parameters, we can use **linear least squares**, which aims to minimize the total square error in

$$
\begin{align}E=\frac{1}{2}\sum^N*{p=1}{\epsilon^2_p}=\frac{1}{2}\sum^N*{p=1}(d_p-y_p)^2\end{align}
$$

The derivation of this is not nice. For an m-dimensional input variable, we can define $w$ and $x_p$ which are our weight vector and p-th input vector, respectively. Now, our equation is \begin{align}E=\sum^N\*{p=1}(d_p-w^Tx_p)^2\\=\lVert d-Xw\rVert^2\end{align}

After derivations, we are left with $w=(X^TX)^{-1}X^Td$, also known as the normal equation. While easy to implement and fast, the inverse of the matrix is expensive to compute (we often use estimated inverse) and we need to use the batch approach, where all of our training data is used at once. It is not iterative, so it may be expensive to try to run all at once.

This section covers Chapter 1, sections 1.1, 1.2, 1.3, 1.5, 1.6, and 1.7.
