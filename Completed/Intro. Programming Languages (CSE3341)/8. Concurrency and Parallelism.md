## Mechanisms

Every **thread** has its own stack and **shares memory** with other threads within the same process. Compilers compile as if every program is single-threaded.

We [[17. Process Synchronization#Synchronization Hardware|synchronize processes]] together by using operations such as locks to ensure mutual exclusion, ordering, and visibility. **Locks** provide *acquire* and *release* functions that allow us to lock and unlock access to variables, preventing accidental concurrency issues when accessing the same variables in shared memory.

## Locks

### Java Locks

Java locks need atomic operations like **test-and-set** to implement locks. A fence is needed for visibility, and the compiler obeys "roach motel" rules where operations are allowed to move into but not out of atomic blocks.

Java locks are **reentrant**, so more than one bit is actually used to keep track of the nesting depth. Spin, or non-blocking locks are converted to blocking locks if there is contention.

## Data Race

A **data race** is the event of two accesses made to the same variable with at least one write. One access doesn't happen before the other, so the result depends on whichever access and writes occur first.

**Data race freedom** is our goal, meaning our program is data race-free.

Modern language **memory models** (DRF0) assume that:

- Instructions appear to execute in an order respecting program order.
- Data races only come from possibly weak or undefined semantics.

This means that modern languages allow for data races. This is intended behavior because the compiler is designed to avoid certain optimizations that could accidentally prevent intended concurrency. It has to allow the program to create data races to preserve synchronization and program order.

## Atomicity

**Atomicity** occurs when operations appear to happen all at once or not at all. [[10. Transaction Management#Performance Optimizations|Serializability]] is the execution equivalent to some serial execution of atomic blocks.

