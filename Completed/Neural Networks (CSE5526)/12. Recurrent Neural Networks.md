---
id: 11. Recurrent Neural Networks
aliases: []
tags: []
---
## Recurrent Neural Networks
Recurrent neural networks are designed to handle sequential data by maintaining a "memory" of the previous outputs. At some point within the network, the output from one part of the network is stored and fed back in during the next cycle as input data at another layer (the loops do not need to be strictly input and output layers).

**Loops** (or cycles) are feedback neurons or layers that pass information from a previous cycle back into the network for the next. Compared to feed-forward networks, RNNs are much more suited (ideal, even) for variable-length inputs while feed-forward networks are only suited for strict-length inputs.

Dealing with recurrent networks, we may simplify the diagrams of our networks by shrinking and describing each layer as one neuron and unfolding recurrent connections over time.

![[Folded RNN.png]]![[Unfolded RNN.png]]

## Hidden Units
Recurrent neural networks aim to solve problems that deal with sequential data and data with variable length. They take previous outputs, known as their hidden states, as inputs and apply them with new information to produce a new response.

RNNs use a special type of layer called a **recurrent hidden unit (RHU)**. They pass their latest output backward to the same or previous layer for use in the next sequence. This effectively simulates a *memory* for the network. We can think of this as an extra set of weights.
## RHU Error Calculation
When calculating the error for a recurrent hidden unit, our error function does not change. Instead, we have to consider error calculation about time as well. In our error function, our desired and actual outputs $d$ and $y$ become $d^{(t)}$ and $y^{(t)}$, where $(t)$ is the sequence index at time $t$. Afterward, we sum the whole sequence to produce our **sequence error** and **total data error** from the sum of our sequence errors. Sequence error is calculated over a sequence, such as a video, and is expressed as $E_s=\sum_{t=1}^T{E^{(t)}(y^{(t)},d^{(t)})}$. Our total data error is expressed by $E_\text{total}=\sum^S_{s=1}E_s$.
## Backpropagation Through Time
Like before with DNNs, we use backpropagation to train our RNNs. To start, we want to make sure that we have and are observing our unfolded network. We treat our RNN as a DNN except with an additional dimension $T$. For each layer, we let the weights be the same.

Next, we need to calculate the gradients for backpropagation. We need to find the output, hidden-to-hidden, and input gradients. Start by defining each gradient's respective weight update functions. Also, write down the forward-pass formulas to help develop the solution.

The **input** and **output** gradients are simple to calculate. Just use the chain rule as normal. The recurrent gradient calculations are more complicated, however. We use $\frac{\partial E^{(t)}}{\partial W}=\frac{\partial E_\text{for}^{(t+1)}}{\partial W}+\frac{\partial E^{(t)}_\text{out}}{\partial W}$. Really, our gradient is just the sum of the next time sequence's error and the error of the output.

## Alternative Architectures
The main architecture that we use passes the hidden state from the same hidden layer to itself in the next time sequence. Other implementations return the network's output to the hidden layer, instead. This results in a less powerful model, but it allows the network to pass any information that it wants to the next iteration. Next, we may use a **single-output** RNN. This version only has one output, returning a single result at the end of the sequence. Typically, this architecture is useful for content summarization.

More in general, we define RNN configurations as a (one or many)-to-(one or many) network.

| **Previous**: [[11. Sequential DNNs]] | **Next**: [[13. Attention]] |
| ------------------------------------- | --------------------------- |