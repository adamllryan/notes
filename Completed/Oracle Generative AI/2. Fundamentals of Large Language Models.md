Goals of this module:

- Explain the fundamentals of LLMs
- Understand LLM architectures
- Design and use prompts for LLMs
- Understand LLM fine-tuning techniques
- Understand fundamentals of code models, multi-modal, and language agents

## LLM Architectures

We will focus on **encoders** and **decoders**, which are responsible for embedding and text generation, respectively. All models (including encoders and decoders) are built on the transformer architecture. An embedding is a numerical representation of text (or other data) that attempts to encode the meaning of that text. We consider the **size** of the model to be the number of trainable parameters that it has.

For each word in a sentence, an encoder produces a vector representation of that word along with words that have previously occurred. The representations are designed to be consumed by other models, and more recently into vector databases for use in semantic search. This allows us to provide a snippet of text and retrieve documents from a vector database that are semantically similar to our original text.

Decoders (GPT, LLama, etc) produce one token at a time. We feed in a sequence of tokens and invoke it to produce the next token. Then, we append the newly created token to the end of the input sequence and repeat. However, this is very expensive.

## Prompting
**Prompting** does not change the model's parameters. It is the simplest way to affect the distribution over a vocabulary. We conduct prompting by altering the input in different ways, such as adding instructions or examples.

**Prompt Engineering** is the process of iteratively refining a prompt for the purpose of eliciting a style of response or distribution of responses. Prompt engineering is often unintuitive and not guaranteed to work, but it often does. It often gives us effective results and there are multiple tested prompt design strategies that exist.

Two of the most popular strategies are in-context learning and few-shot prompting. **In-context learning** attempts to condition an LLM with instructions and/or demonstrations of the task it is meant to complete, otherwise known as showing the LLM how to complete its task. Similarly, **k-shot prompting** explicitly provides k examples of the intended task in the prompt. Few-shot prompting is believed to improve results over 0-shot prompting.

**Chain-of-thought** is a technique where we prompt the LLM to emit intermediate reasoning steps to show how it reached an answer. We think that it emulates reasoning in a nice and realistic way. **Least-to-most** is a similar prompting technique where we instruct the LLM to try to decompose the problem into sub-tasks and solve them, beginning with the easiest first. **Step-back** is a prompt technique where we instruct the LLM to identify high-level concepts pertinent to a specific task.

### Malicious Prompt Engineering

Prompt injection (or jailbreaking) is an attempt to deliberately provide an LLM with input to ignore instructions, cause harm, or behave in a different way than expected in deployment.

## Training

Prompting on its own may be inappropriate when:

- training data exists.
- domain-adaptation is required.
**Domain-adaptation** is the act of adapting a model, typically via training, to enhance performance outside the domain or subject-area it was originally trained on. We use four main styles of weight updates:
 ![[Pasted image 20240730110142.png]]
 Low-rank adaptation (Lora) keeps the parameters of the model fixed but adds additional parameters that will be trained. Correctly choosing training styles is very important due to the costs associated with each method:
 ![[Pasted image 20240730111314.png]]

## Decoding
**Decoding** is the technical term for generating text. Since decoding happens iteratively, we need to figure out a way to decide which word to choose out of the probability distribution we receive as output. The cheapest and most common choice is to use the **[[03_informed_search#Greedy Search|greedy]]** choice, where we simply choose the word with the highest probability of being correct. **Non-deterministic** decoding incorporates a sampled randomness to picking tokens, where we use a **temperature** hyperparameter that modulates the distribution of the vocabulary. A lower temperature means the distribution is *peaked* more around the most likely word, or it will more likely be the most likely word. Increasing temperature gives us a more random response, or it flattens the curve. **Beam search** is a third method where we generate multiple sequences at the same time and prune as we go. It takes the greedy result of multiple trees, so we get the speed of greedy search and the highest probability of a whole sentence instead of next likely word.

### Hallucination
**Hallucination** is a phenomenon where generated text is non-factual and/or is ungrounded. Often times, the hallucination is subtle and hard to detect. We consider grammatically incorrect sentences and incorrect information to be hallucinations. There are no ways to guaranteed-eliminate hallucinations, but there are some mitigation strategies. We measure **groundedness**, or the extent to which generated text is supported by the document it draws upon, and **attributability**, or being able to attribute information to parts of a document, to determine if text is a hallucination. We refer to generated text as **grounded** in a document if the document supports a text.

## Applications
**Retrieval augmented generation** is primarily used in QA (as well as dialogue, fact-checking, slot filling, and entity linking), where we give the model a document and query and receive a response containing the answer from the source document. It is claimed to be less prone to hallucinations and lets us reuse the same model between different documents. It is **non-parametric** (in theory) meaning the same model is able to answer questions about any corpus. It is also able to be trained end-to-end, or as a single model instead of in multiple parts.

**Code models** are trained on code and comments/documentation. Typically, it is used to generate code based off of comments and is usually easier to train than natural language due to its narrower scope and more defined structure. Some of the most successful applications of generative AI responses, 85% of copilot users feel they are more productive due to this tool. However, it is noted that it often fails when we ask it to patch bugs.

**Multi-modal** models are trained on multiple forms of media (modalities) and may be autoregressive or diffusion-based. Autoregressive models produce output token-by-token meanwhile diffusion models can produce the whole output simultaneously and refine over multiple passes. Diffusion-based text models are not very successful because text is categorical.

**Language agents** are a new area of research where we use LLM-based agents to create plans, reason, and take action based on these created plans and reasoning.