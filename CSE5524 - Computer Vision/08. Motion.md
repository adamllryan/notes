## Motion

Motion is the change in position of an object in a sequence of images. Essentially, it is the change in pixels in that sequence of images over time. Typically, we deal with two scenarios: still and moving cameras. We also need to consider the amount of objects moving in a scene.

### Image Differencing

**Image differencing** is a simple method to detect motion. It is the process of subtracting one image from another. The result is a new image that shows the difference between the two images. The difference is then thresholded and then we have our result. This is useful for detecting motion in a scene where the camera is not moving. Image differencing is good for detecting motion _presence_, but not with direction.

How do we determine a threshold? We can use a fixed threshold, but this is not always the best option. We can also use a dynamic threshold, which is based on the mean and standard deviation of the pixel values. This is useful for scenes with varying lighting conditions. For a constant threshold, we compute the change as:

$$
\Delta I = \begin{cases}
    1 & \text{if } |I_t - I_{t-1}| > T \\
    0 & \text{otherwise}
\end{cases}
$$

where $I_t$ is the current frame and $I_{t-1}$ is the previous frame. $T$ is the threshold. If we use a dynamic threshold, we do:

$$
\Delta I = \begin{cases}
    1 & \text{if } |I_t - I_{t-1}| > \mu + k\sigma \\
    0 & \text{otherwise}
\end{cases}
$$

where $\mu$ is the mean and $\sigma$ is the standard deviation. $k$ is a constant that we can set.

### Weber's Law

Weber's Law states that the just noticeable difference (JND) between two stimuli is proportional to the magnitude of the stimuli. This is useful for determining the threshold for image differencing. We can use the following formula to determine the threshold:

$$
T = k \cdot \frac{\Delta I}{I}
$$

where $T$ is the threshold, $k$ is a constant, $\Delta I$ is the change in intensity, and $I$ is the intensity of the pixel.

### Optical Flow

**Optical flow** is the pattern of apparent motion of objects, surfaces, and edges in a visual scene caused by the relative motion between an observer and a scene. It is the apparent motion of objects in a scene due to the relative motion between the observer and the scene. Optical flow is a 2D vector field where each vector is a displacement vector showing the movement of points from one frame to the next. It is a useful tool for understanding the motion of objects in a scene. It is also useful for understanding the 3D structure of the scene.

In a given sequence of images: if we take a single pixel at a location $(x,y)$ and observe it at another location in another sequence, then it will have the same brightness constancy. This will fail if the object moves into shadow.

The **brightness constancy constraint** states that the brightness of a pixel does not change between frames. This is a reasonable assumption for most scenes. The **spatial coherence constraint** states that the motion of a pixel is similar to the motion of its neighbors. This is also a reasonable assumption for most scenes. It can be written as the formula:

$$
I(x,y,t) = I(x + \Delta x, y + \Delta y, t + \Delta t)
$$

where $I(x,y,t)$ is the intensity of the pixel at location $(x,y)$ at time $t$. $\Delta x$ and $\Delta y$ are the displacements in the $x$ and $y$ directions, respectively. $\Delta t$ is the time difference between the two frames.

### Aggregate Optical Flow

**Aggregate optical flow** is the average of the optical flow vectors in a region. This is useful for understanding the motion of objects in a scene. We can use the following formula to compute the aggregate optical flow:

$$
E=\sum_{i=1}^{n}(f_{xi}u+f_{yi}+f_{ti})^2\\

\frac{ \partial E}{\partial u} = \sum_{i=1}^{n}2(f_{xi}u+f_{yi}+f_{ti})f_{xi} = 0\\

u = -\frac{\sum_{i=1}^{n}f_{xi}f_{ti}}{\sum_{i=1}^{n}f_{xi}^2}
$$

where $E$ is the error, $f_{xi}$ and $f_{yi}$ are the $x$ and $y$ components of the optical flow vector, respectively. $f_{ti}$ is the time component of the optical flow vector. $u$ is the aggregate optical flow.

This can be written in matrix form as:

$$
\begin{bmatrix}
    \sum f_{xi}^2 & \sum f_{xi}f_{yi} \\
    \sum f_{xi}f_{yi} & \sum f_{yi}^2
\end{bmatrix}
\begin{bmatrix}
    u \\
    v
\end{bmatrix}
=
-\begin{bmatrix}
    \sum f_{xi}f_{ti} \\
    \sum f_{yi}f_{ti}
\end{bmatrix}
$$

where $u$ and $v$ are the $x$ and $y$ components of the aggregate optical flow vector, respectively.

This effectively averages the pixels to find a center of mass for the motion. It is very similar to smoothing.

### Normal Optical Flow

**Normal optical flow** is the optical flow vector at a single pixel. We can use the following formula to compute the normal optical flow:

$$
\begin{bmatrix}
    f_{x} & f_{y} \\
    f_{y} & f_{t}
\end{bmatrix}
\begin{bmatrix}
    u \\
    v
\end{bmatrix}
=
-\begin{bmatrix}
    f_{t} \\
    f_{t}
\end{bmatrix}
$$

where $f_{x}$ and $f_{y}$ are the $x$ and $y$ components of the optical flow vector, respectively. $f_{t}$ is the time component of the optical flow vector. $u$ and $v$ are the $x$ and $y$ components of the normal optical flow vector, respectively.

## Aperture Problem

The **aperture problem** is a problem in computer vision where the motion of an object is not fully visible. This is because the motion of the object is not fully visible in the aperture of the camera.

### Weighted Aggregate Normal Flow

**Weighted aggregate normal flow** is the average of the normal optical flow vectors in a region. This is useful for understanding the motion of objects in a scene. We can use the following formula to compute the weighted aggregate normal flow:

$$
\begin{bmatrix}
    \sum w^2f_{xi}^2 & \sum w^2f_{xi}f_{yi} \\
    \sum w^2f_{xi}f_{yi} & \sum w^2f_{yi}^2
\end{bmatrix}
\begin{bmatrix}
    u \\
    v
\end{bmatrix}
=
-\begin{bmatrix}
    \sum w^2f_{xi}f_{ti} \\
    \sum w^2f_{yi}f_{ti}
\end{bmatrix}
$$

where $w$ is the weight of the pixel. $f_{xi}$ and $f_{yi}$ are the $x$ and $y$ components of the optical flow vector, respectively. $f_{ti}$ is the time component of the optical flow vector. $u$ and $v$ are the $x$ and $y$ components of the weighted aggregate normal flow vector, respectively.

Overall, optical flow lets us track one-pixel's worth of motion per frame, meaning our ability to track motion is dependent on frame rate. So how do we track more?

### Hierarchical Motion Estimation

**Hierarchical motion estimation** is the process of estimating motion at multiple scales. If we downscale an image, we are able to apply optical flow with less pixels, meaning that lower scale pixel is actually representative of many more, just combined as one. It isn't as accurate, but it lets us handle larger distances. The key element of this, however, is to just replicate this over multiple scales to handle all cases.

We can use image pyramids to estimate motion at multiple scales. An **image pyramid** is a multi-scale representation of an image. It is useful for understanding the structure of an image at different scales. We can use the following formula to compute an image pyramid:

The difference between two levels ends up being the error between them. We use the same process as in image pyramids for our approach.

### Motion Energy Image

**Motion energy image** is a representation of the motion in a sequence of images. It is useful for understanding the motion of objects in a scene. We can use the following formula to compute the motion energy image:

$$
E(x,y,t) = \sum_{i=1}^{n}D(x,y,t-i)
$$

where $D(x,y,t)$ is the difference image at location $(x,y)$ at time $t$. $E(x,y,t)$ is the motion energy image at location $(x,y)$ at time $t$. $D$ is a general function to represent whatever function we choose to represent the difference between images.

MEI is the operation of logical ORing on the difference images.

### Motion History Image

**Motion history image** is a representation of the motion in a sequence of images. It is useful for understanding the motion of objects in a scene. We can use the following formula to compute the motion history image:

MHI is the operation of MAXing on the difference images. It checks for the latest movement, along with the history of movement from past MHIs. If there is movement, any old movement will be overwritten.

$$
H(x,y,t) = \begin{cases}
    T & \text{if } D(x,y,t) = 1 \\
    \text{max}(H(x,y,t-1)-1,0) & \text{otherwise}
\end{cases}
$$

where $D(x,y,t)$ is the difference image at location $(x,y)$ at time $t$. $H(x,y,t)$ is the motion history image at location $(x,y)$ at time $t$. $T$ is a constant that we can set.

#### MHI Normalization

We can normalize the motion history image to improve its contrast. We can use the following formula to normalize the motion history image:

$$
H(x,y,t) = \frac{H(x,y,t)}{T}
$$

where $H(x,y,t)$ is the motion history image at location $(x,y)$ at time $t$. $T$ is a constant that we can set.

For a single pixel, we can use the following formula to compute the motion history image:

$$
max(0,\frac{t-[\text{min}(t)-\Delta t]}{\text{max}(t)-[\text{min}(t)-\Delta t]})
$$

where $t$ is the time of the current frame. $\Delta t$ is the time difference between the current frame and the previous frame. $\text{min}(t)$ and $\text{max}(t)$ are the minimum and maximum times, respectively. $\text{min}(t)$ is representative of the oldest frame that we want to keep.
