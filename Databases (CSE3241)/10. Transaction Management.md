# A simple database model
A *database* is simply a collection of named data items. *Data granularity* refers to a field, a record, a table, or a whole disk block. The set of valid operations are *retrieve*, *change*, *read*, and *write*. 

# Transactions
A *transaction* is a logical unit of database processing. It is a set of [[Operations|operations]] that includes at least one *access* operation (read/write/delete). 

For example, the process of moving money from a savings account to a checking account would require the following transaction: 

``` Sample transaction
Read balance from checking
Read balance from savings
savings balance -= value
checking balance += value
Write balance to checking
Write balance to savings
```

Databases can receive transactions in any order, at the same time. This means a DBMS must be able to handle requests *concurrently*. 

Transactions may be submitted interactively or embedded within a program, and an application program may contain several transactions. It must have a begin and end boundary. 

Transactions have a set of basic operations:
- `read_item(X)`: reads DB.X into a variable
- `write_item(X)`: writes variable into DB.X

# Concurrency Control
We need to ensure that processes accessing the database concurrently behave correctly. We use the acronym *ACID* to handle concurrency in a database: 

**A**tomic - A transaction must be entirely performed or not at all. No half-completed. 
**C**onsistent - Transactions that begin with the database in a consistent state should end with a database in the same state. 
**I**solated - Transactions should always function as if they were executing in isolation away from every other transaction. 
**D**urable - Database changes made by a *completed* transaction should persist, even if the database fails. 
# Points of failure in Concurrency Control

When two processes update the same piece of data, we call that *lost update*. Both read a value, one updates, and then the other updates on top of it, resulting in the loss of the first update. 

When a summary process runs while a value is being updated, it can result in an *incorrect summary*. 

A *dirty read* or *temporary update* is when a process writes a changed value, another reads it, and then the first one fails and reverts to before. Then the second process has the updated value however it is unchanged in the database. 

What causes failures in transactions?
- Computer failure, such as crashes
- Transaction/System Errors such as overflow or underflow
- Logical or Exception Errors, such as insufficient funds in a banking transaction
- Disk failure
In the event of a failure, it is the job of the [[Transaction Manager]] to protect the data from loss and damage. 

# SQL Transaction Processing

In SQL, any transaction may have any number of read-and-write operations. It begins with a `BEGIN TRANSACTION` statement. Afterward, all transactions are run *without* committing. If at any point a transaction fails, `IF error THEN ROLLBACK;`. Once all operations are completed, it moves to a *partially committed* state. This allows it to roll back to this state in case of a failure. Once completed, `COMMIT;` and `END TRANSACTION;` complete the whole transaction. 

Here are some additional SQL transaction commands:
- `COMMIT [|TRANSACTION]`
- `REDO`
- `ROLLBACK [|TRANSACTION]`

How do we implement it?

A DBMS keeps a *system log* of transactions in the form of a sequential, append-only file. It is kept on disk and in the event of a failure, the system log can "playback" transactions up until failure. 

# Transaction Schedules
We denote [[Transaction Schedules]] as the order of reads and writes given a set of transactions. It can be written as a graph or in text, where it would be formatted like this: $S_a:r_1(X);w_1(X);$
where $S_a$ is a schedule, and $r_1$ reads X as Transaction 1. 

Two operations in a schedule can conflict if they *belong* to *different* transactions, *operate* on the *same* item, and at least *one* operation is a *write*.

We consider a schedule a *complete schedule* if:
- All operations are exactly as in the transactions
- Every pair of operations in one transaction has the same schedule order
- Any pairs of conflicting operations must occur at different times in the schedule

NOTE: a complete schedule only requires that *conflicting operations* have total ordering. However, every transaction must retain the same operation ordering in itself. 

# Schedule Recovery

We characterize schedules by ease of recovery. Our goal is to avoid schedules where recovery is impossible but instead simple. 

Our rule is that *once a transaction T is committed, it should never be necessary to roll back T*. This ensures ACID is followed and a schedule T is recoverable. 

If a schedule has only transactions that read after transactions have been committed, that is a *cascade-less rollback* schedule. And if a schedule executes transactions in series, then it is a **serial** schedule. 

# Performance Optimizations

We want to be able to interleave processes while preserving correctness so that we can save time and maximize our processor efficiency. 

A **serializable** schedule is a schedule that is equivalent to a *serial* schedule of the same n transactions. 

A better test for equivalence is *conflict equivalence*, where we make sure that two schedules have the same operations and they have the same order of any two conflicting operations. We can call a schedule *conflict serializable* if it is conflict equivalent to some serial schedule. 

A method to test this is to construct a [[Precedence Graph|precedence graph]]. 

